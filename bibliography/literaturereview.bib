% Encoding: UTF-8

@Book{efron2016,
  author    = {Efron, Bradley and Hastie, Trevor},
  title     = {Computer Age Statistical Inference},
  year      = {2016},
  date      = {2016-07-31},
  volume    = {5},
  publisher = {Cambridge University Press},
  isbn      = {1107149894},
  url       = {https://www.ebook.de/de/product/26311758/bradley_efron_trevor_hastie_computer_age_statistical_inference.html},
  ean       = {9781107149892},
  file      = {:efron2016 - Computer Age Statistical Inference.pdf:PDF},
}

@Book{rasmussen2005,
  author       = {Carl Edward Rasmussen and Christopher K. I. Williams},
  title        = {Gaussian Processes for Machine Learning},
  year         = {2005},
  date         = {2005-11-11},
  volume       = {38},
  publisher    = {MIT University Press Group Ltd},
  isbn         = {026218253X},
  pages        = {715--719},
  url          = {https://www.ebook.de/de/product/5192092/carl_edward_rasmussen_gaussian_processes_for_machine_learning.html},
  ean          = {9780262182539},
  file         = {:rasmussen2005 - Gaussian Processes for Machine Learning.pdf:PDF},
  journaltitle = {The MIT Press, Cambridge, MA, USA},
}

@Book{burger2018,
  author    = {Burger, Scott V.},
  title     = {Introduction to Machine Learning with R},
  year      = {2018},
  date      = {2018-04-11},
  publisher = {O'Reilly UK Ltd.},
  isbn      = {1491976446},
  pagetotal = {200},
  url       = {https://www.ebook.de/de/product/29963177/scott_v_burger_introduction_to_machine_learning_with_r.html},
  ean       = {9781491976449},
  file      = {:burger2018 - Introduction to Machine Learning with R.pdf:PDF},
}

@Book{drewconway2012,
  author    = {Drew Conway, John Myles White},
  title     = {Machine Learning for Hackers},
  year      = {2012},
  date      = {2012-04-11},
  publisher = {O'Reilly UK Ltd.},
  isbn      = {1449303714},
  pagetotal = {320},
  url       = {https://www.ebook.de/de/product/16540839/drew_conway_john_myles_white_machine_learning_for_hackers.html},
  ean       = {9781449303716},
  file      = {:drewconway2012 - Machine Learning for Hackers.pdf:PDF},
}

@Article{gu2018,
  author       = {Gu, Jiuxiang and Wang, Zhenhua and Kuen, Jason and Ma, Lianyang and Shahroudy, Amir and Shuai, Bing and Liu, Ting and Wang, Xingxing and Wang, Gang and Cai, Jianfei and Chen, Tsuhan},
  title        = {Recent advances in convolutional neural networks},
  journaltitle = {Pattern Recognition},
  date         = {2018-05},
  volume       = {77},
  pages        = {354--377},
  doi          = {10.1016/j.patcog.2017.10.013},
  file         = {:gu2018 - Recent Advances in Convolutional Neural Networks.pdf:PDF},
  publisher    = {Elsevier BV},
}

@Article{laengkvist2014,
  author       = {Längkvist, Martin and Karlsson, Lars and Loutfi, Amy},
  title        = {A review of unsupervised feature learning and deep learning for time-series modeling},
  journaltitle = {Pattern Recognition Letters},
  date         = {2014-06},
  volume       = {42},
  pages        = {11--24},
  doi          = {10.1016/j.patrec.2014.01.008},
  file         = {:laengkvist2014 - A Review of Unsupervised Feature Learning and Deep Learning for Time Series Modeling.pdf:PDF},
  publisher    = {Elsevier BV},
}

@Article{liu2017,
  author       = {Weibo Liu and Zidong Wang and Xiaohui Liu and Nianyin Zeng and Yurong Liu and Fuad E. Alsaadi},
  title        = {A survey of deep neural network architectures and their applications},
  journaltitle = {Neurocomputing},
  date         = {2017-04},
  volume       = {234},
  pages        = {11--26},
  doi          = {10.1016/j.neucom.2016.12.038},
  file         = {:liu2017 - A Survey of Deep Neural Network Architectures and Their Applications.pdf:PDF},
  publisher    = {Elsevier BV},
}

@Article{guo2016,
  author       = {Guo, Yanming and Liu, Yu and Oerlemans, Ard and Lao, Songyang and Wu, Song and Lew, Michael S.},
  title        = {Deep learning for visual understanding: A review},
  journaltitle = {Neurocomputing},
  date         = {2016-04},
  volume       = {187},
  pages        = {27--48},
  doi          = {10.1016/j.neucom.2015.09.116},
  file         = {:guo2016 - Deep Learning for Visual Understanding_ a Review.pdf:PDF},
  publisher    = {Elsevier BV},
}

@Article{prieto2016,
  author       = {Alberto Prieto and Beatriz Prieto and Eva Martinez Ortigosa and Eduardo Ros and Francisco Pelayo and Julio Ortega and Ignacio Rojas},
  title        = {Neural networks: An overview of early research, current frameworks and new challenges},
  journaltitle = {Neurocomputing},
  date         = {2016-11},
  volume       = {214},
  pages        = {242--268},
  doi          = {10.1016/j.neucom.2016.06.014},
  file         = {:prieto2016 - Neural Networks_ an Overview of Early Research, Current Frameworks and New Challenges.pdf:PDF},
  publisher    = {Elsevier BV},
}

@Article{litjens2017,
  author       = {Litjens, Geert and Kooi, Thijs and Bejnordi, Babak Ehteshami and Setio, Arnaud Arindra Adiyoso and Ciompi, Francesco and Ghafoorian, Mohsen and van der Laak, Jeroen A. W. M. and van Ginneken, Bram and Sánchez, Clara I.},
  title        = {A survey on deep learning in medical image analysis},
  journal      = {Medical Image Analysis},
  journaltitle = {Medical Image Analysis},
  year         = {2017},
  date         = {2017-12},
  volume       = {42},
  month        = dec,
  pages        = {60--88},
  doi          = {10.1016/j.media.2017.07.005},
  file         = {:litjens2017 - A Survey on Deep Learning in Medical Image Analysis.pdf:PDF},
  publisher    = {Elsevier BV},
}

@Manual{allaire2018,
  author = {Allaire, J. J. and Chollet, Fran{\c{c}}ois},
  title  = {keras: R Interface to `Keras'},
  date   = {2018},
  note   = {R package version 2.2.0},
  url    = {https://CRAN.R-project.org/package=keras},
}

@Manual{rct2018,
  author       = {{R Core Team}},
  title        = {R: A Language and Environment for Statistical Computing},
  date         = {2018},
  organization = {R Foundation for Statistical Computing},
  location     = {Vienna, Austria},
  url          = {https://www.R-project.org/},
  keywords     = {rank1},
}

@Article{lecun2015,
  author       = {LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
  title        = {Deep learning},
  journaltitle = {Nature},
  date         = {2015-05},
  volume       = {521},
  number       = {7553},
  pages        = {436--444},
  doi          = {10.1038/nature14539},
  file         = {:lecun2015 - Deep Learning.pdf:PDF},
  publisher    = {Springer Nature},
}

@Book{morgan2018,
  author = {Peter Morgan},
  title  = {Machine Learning Is Changing the Rules},
  date   = {2018},
  file   = {:morgan2018 - Machine Learning Is Changing the Rules.pdf:PDF},
}

@Book{rosenblatt1957,
  author    = {Rosenblatt, Frank},
  title     = {The perceptron, a perceiving and recognizing automaton},
  date      = {1957},
  publisher = {Cornell Aeronautical Laboratory},
  file      = {:rosenblatt1957 - The Perceptron, a Perceiving and Recognizing Automaton.pdf:PDF},
}

@Article{rosenblatt1958,
  author       = {Rosenblatt, Frank},
  title        = {The perceptron: A probabilistic model for information storage and organization in the brain.},
  journaltitle = {Psychological Review},
  date         = {1958},
  volume       = {65},
  number       = {6},
  pages        = {386--408},
  doi          = {10.1037/h0042519},
  file         = {:rosenblatt1958 - The Perceptron_ a Probabilistic Model for Information Storage and Organization in the Brain..pdf:PDF},
  publisher    = {American Psychological Association},
}

@Book{bishop1995,
  author    = {Bishop, Christopher M.},
  title     = {Neural Networks for Pattern Recognition},
  year      = {1995},
  date      = {1995-11-11},
  publisher = {Oxford University Press},
  isbn      = {0198538642},
  pagetotal = {500},
  url       = {https://www.ebook.de/de/product/3242184/christopher_m_bishop_neural_networks_for_pattern_recognition.html},
  comment   = {Lent to me by Peter Challenor},
  ean       = {9780198538646},
  keywords  = {rank5},
}

@Article{widrow1990,
  author       = {Widrow, B. and Lehr, M. A.},
  title        = {30 years of adaptive neural networks: perceptron, Madaline, and backpropagation},
  journaltitle = {Proceedings of the IEEE},
  date         = {1990},
  volume       = {78},
  number       = {9},
  pages        = {1415--1442},
  doi          = {10.1109/5.58323},
  file         = {:widrow1990 - 30 Years of Adaptive Neural Networks_ Perceptron, Madaline, and Backpropagation.pdf:PDF},
  publisher    = {Institute of Electrical and Electronics Engineers (IEEE)},
}

@Article{block1970,
  author       = {H. D. Block},
  title        = {A review of ``Perceptrons: An Introduction to Computational Geometry''},
  journaltitle = {Information and Control},
  date         = {1970-12},
  volume       = {17},
  number       = {5},
  pages        = {501--522},
  doi          = {10.1016/s0019-9958(70)90409-2},
  file         = {:block1970 - A Review of ``Perceptrons_ an Introduction to Computational Geometry''.pdf:PDF},
  keywords     = {rank5},
  publisher    = {Elsevier BV},
  timestamp    = {2018-11-02},
}

@Book{ivakhnenko1965,
  author    = {A. G. Ivakhnenko and V. G. Lapa},
  title     = {Cybernetic predicting devices},
  date      = {1965},
  publisher = {CCM Information Corporation},
  comment   = {first functional example of deep learning},
}

@InProceedings{williams1996,
  author    = {Williams, Christopher K. I. and Rasmussen, Carl Edward},
  title     = {Gaussian Processes for Regression},
  booktitle = {Advances in neural information processing systems},
  date      = {1996},
  pages     = {514--520},
  abstract  = {Neural Information Processing Systems http://nips.cc/},
  file      = {:williams1996 - Gaussian Processes for Regression.pdf:PDF},
  timestamp = {2018-11-19},
}

@Article{cressie1990,
  author       = {Noel Cressie},
  title        = {The Origins of Kriging},
  journaltitle = {Mathematical Geology},
  date         = {1990-04},
  volume       = {22},
  number       = {3},
  pages        = {239--252},
  doi          = {10.1007/bf00889887},
  file         = {:cressie1990 - The Origins of Kriging.pdf:PDF},
  publisher    = {Springer Nature},
  timestamp    = {2018-11-20},
}

@Article{krige1951,
  author       = {Krige, Danie G.},
  title        = {A statistical approach to some basic mine valuation problems on the Witwatersrand},
  journaltitle = {Journal of the Southern African Institute of Mining and Metallurgy},
  date         = {1951},
  volume       = {52},
  number       = {6},
  pages        = {119--139},
  file         = {:krige1951 - A Statistical Approach to Some Basic Mine Valuation Problems on the Witwatersrand.pdf:PDF},
  publisher    = {Southern African Institute of Mining and Metallurgy},
  timestamp    = {2018-11-20},
}

@Article{mackay1997,
  author    = {MacKay, David J. C.},
  title     = {Gaussian processes: a replacement for supervised neural networks?},
  date      = {1997},
  file      = {:mackay1997 - Gaussian Processes_ a Replacement for Supervised Neural Networks_.pdf:PDF},
  publisher = {Citeseer},
  timestamp = {2018-11-20},
}

@Article{gandin1966,
  author       = {Gandin, Lev Semenovich},
  title        = {Objective analysis of meteorological fields},
  journaltitle = {Quarterly Journal of the Royal Meteorological Society},
  date         = {1966-07},
  translator   = {Mif`al tirgume ha-mada` ha Yi{\'{s}}re'eli},
  volume       = {92},
  number       = {393},
  pages        = {447--447},
  doi          = {10.1002/qj.49709239320},
  publisher    = {Wiley},
  timestamp    = {2018-11-20},
}

@Article{schmidhuber2015,
  author       = {Jürgen Schmidhuber},
  title        = {Deep learning in neural networks: An overview},
  journaltitle = {Neural Networks},
  date         = {2015-01},
  volume       = {61},
  pages        = {85--117},
  doi          = {10.1016/j.neunet.2014.09.003},
  file         = {:schmidhuber2015 - Deep Learning in Neural Networks_ an Overview.pdf:PDF},
  publisher    = {Elsevier BV},
}

@Article{matheron1963,
  author       = {Matheron, Georges},
  title        = {Principles of geostatistics},
  journal      = {Economic geology},
  journaltitle = {Economic Geology},
  year         = {1963},
  date         = {1963-12},
  volume       = {58},
  number       = {8},
  pages        = {1246--1266},
  doi          = {10.2113/gsecongeo.58.8.1246},
  file         = {:matheron1963 - Principles of Geostatistics.pdf:PDF},
  keywords     = {applications,economic geology,geostatistics,Geostatistics, principles,statistical analysis},
  publisher    = {Society of Economic Geologists},
  timestamp    = {2018-11-20},
}

@InProceedings{gupta1991,
  author       = {Gupta, Madan M. and Qi, J.},
  title        = {On fuzzy neuron models},
  booktitle    = {{IJCNN}-91-Seattle International Joint Conference on Neural Networks},
  date         = {1991},
  volume       = {2},
  organization = {IEEE},
  publisher    = {{IEEE}},
  pages        = {431--436},
  doi          = {10.1109/ijcnn.1991.155371},
  file         = {:gupta1991 - On Fuzzy Neuron Models.pdf:PDF},
  keywords     = {rank1},
  timestamp    = {2018-11-23},
}

@Article{rumelhart1986,
  author       = {Rumelhart, David E. and Hinton, Geoffrey E. and McClelland, James L.},
  title        = {A general framework for parallel distributed processing},
  journaltitle = {Parallel distributed processing: Explorations in the microstructure of cognition},
  date         = {1986},
  volume       = {1},
  number       = {45-76},
  pages        = {26},
  file         = {:rumelhart1986general - A General Framework for Parallel Distributed Processing.pdf:PDF},
  timestamp    = {2018-11-23},
}

@Article{maass1997,
  author       = {Maass, Wolfgang},
  title        = {Networks of spiking neurons: The third generation of neural network models},
  journaltitle = {Neural Networks},
  date         = {1997-12},
  volume       = {10},
  number       = {9},
  pages        = {1659--1671},
  doi          = {10.1016/s0893-6080(97)00011-7},
  file         = {:maass1997 - Networks of Spiking Neurons_ the Third Generation of Neural Network Models.pdf:PDF},
  keywords     = {rank1},
  publisher    = {Elsevier {BV}},
  timestamp    = {2018-11-23},
}

@Article{matheron1960,
  author       = {Matheron, Georges},
  title        = {Krigeage dun Panneau Rectangulaire par sa P{\'{e}}riph{\'{e}}rie (Kriging a rectangular panel via its perimeter)},
  journaltitle = {Note g{\'e}ostatistique},
  date         = {1960},
  volume       = {28},
  file         = {:MATHERON_Rapport_00034.pdf:PDF},
  timestamp    = {2018-11-24},
}

@Article{sacks1989,
  author       = {Jerome Sacks and William J. Welch and Toby J. Mitchell and Henry P. Wynn},
  title        = {Design and Analysis of Computer Experiments},
  journaltitle = {Statistical Science},
  date         = {1989},
  volume       = {4},
  number       = {4},
  pages        = {409--423},
  issn         = {0883-4237},
  url          = {http://www.jstor.org/stable/2245858},
  abstract     = {Many scientific phenomena are now investigated by complex computer models or codes. A computer experiment is a number of runs of the code with various inputs. A feature of many computer experiments is that the output is deterministic--rerunning the code with the same inputs gives identical observations. Often, the codes are computationally expensive to run, and a common objective of an experiment is to fit a cheaper predictor of the output to the data. Our approach is to model the deterministic output as the realization of a stochastic process, thereby providing a statistical basis for designing experiments (choosing the inputs) for efficient prediction. With this model, estimates of uncertainty of predictions are also available. Recent work in this area is reviewed, a number of applications are discussed, and we demonstrate our methodology with an example.},
  file         = {:sacks1989 - Design and Analysis of Computer Experiments.pdf:PDF},
  publisher    = {Institute of Mathematical Statistics},
  timestamp    = {2018-11-25},
}

@Article{kennedy2001,
  author       = {Kennedy, Marc C. and O'Hagan, Anthony},
  title        = {Bayesian calibration of computer models},
  journaltitle = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
  date         = {2001-08},
  volume       = {63},
  number       = {3},
  pages        = {425--464},
  doi          = {10.1111/1467-9868.00294},
  abstract     = {Journal of the Royal Statistical Society: Series B (Statistical Methodology) 2001.63:425-464},
  file         = {:kennedy2001 - Bayesian Calibration of Computer Models.pdf:PDF},
  publisher    = {Wiley},
  timestamp    = {2018-11-25},
}

@Article{abadi2016,
  author      = {Abadi, Mart{\'{i}}n and Barham, Paul and Chen, Jianmin and Chen, Zhifeng and Davis, Andy and Dean, Jeffrey and Devin, Matthieu and Ghemawat, Sanjay and Irving, Geoffrey and Isard, Michael and Kudlur, Manjunath and Levenberg, Josh and Monga, Rajat and Moore, Sherry and Murray, Derek G. and Steiner, Benoit and Tucker, Paul and Vasudevan, Vijay and Warden, Pete and Wicke, Martin and Yu, Yuan and Zheng, Xiaoqiang},
  title       = {TensorFlow: A system for large-scale machine learning},
  date        = {2016-05-27},
  volume      = {16},
  pages       = {265--283},
  eprint      = {http://arxiv.org/abs/1605.08695v2},
  eprintclass = {cs.DC},
  eprinttype  = {arXiv},
  abstract    = {TensorFlow is a machine learning system that operates at large scale and in heterogeneous environments. TensorFlow uses dataflow graphs to represent computation, shared state, and the operations that mutate that state. It maps the nodes of a dataflow graph across many machines in a cluster, and within a machine across multiple computational devices, including multicore CPUs, general-purpose GPUs, and custom designed ASICs known as Tensor Processing Units (TPUs). This architecture gives flexibility to the application developer: whereas in previous "parameter server" designs the management of shared state is built into the system, TensorFlow enables developers to experiment with novel optimizations and training algorithms. TensorFlow supports a variety of applications, with particularly strong support for training and inference on deep neural networks. Several Google services use TensorFlow in production, we have released it as an open-source project, and it has become widely used for machine learning research. In this paper, we describe the TensorFlow dataflow model in contrast to existing systems, and demonstrate the compelling performance that TensorFlow achieves for several real-world applications.},
  booktitle   = {OSDI},
  file        = {:tensorflow.pdf:PDF},
  keywords    = {cs.DC, cs.AI, rank1},
  timestamp   = {2018-11-25},
}

@Article{philip1986,
  author       = {Philip, G. M. and Watson, D. F.},
  title        = {Matheronian Geostatistics---Quo Vadis?},
  journaltitle = {Mathematical Geology},
  date         = {1986-01},
  volume       = {18},
  number       = {1},
  pages        = {93--117},
  doi          = {10.1007/bf00897657},
  file         = {:philip1986 - Matheronian Geostatistics Quo Vadis_.pdf:PDF},
  publisher    = {Springer Nature},
  timestamp    = {2018-11-25},
}

@Article{krige1962,
  author       = {Krige, Danie G.},
  title        = {Effective pay limits for selective mining},
  journaltitle = {Journal of the Southern African Institute of Mining and Metallurgy},
  date         = {1962},
  language     = {English},
  volume       = {62},
  number       = {6},
  pages        = {345--363},
  issn         = {0038-223X},
  url          = {https://journals.co.za/content/saimm/62/6/AJA0038223X_3698},
  abstract     = {An analysis is made of the various factors affecting the efficiency of selectively mining gold ore a specified pay limit. It is shown that for the most economic basis of selective mining, the mining of some ore valued below the official pay limit is not only permissible but essential; also that where the correlation between the actual values around the peripheries of intact blocks of ore, or parts hereof and the actual values of the ore inside these blocks is relatively low, a substantial improvement in the accuracy of underground sampling could have only a small effect on the efficiency of selective mining. The principles o f correlation and regression are adapted to this problem in order to interpret current stope sampling as well as peripheral or part peripheral sampling results to the best advantage. For this purpose the use of an ï¿12effectiveï¿12 pay limit is advocated, such pay limit being related to but usually well below the official pay limit. },
  file         = {:krige1962 - Effective Pay Limits for Selective Mining.pdf:PDF},
  publisher    = {Southern African Institute of Mining and Metallurgy},
  timestamp    = {2018-11-26},
  type         = {Journal Article},
}

@Article{bachoc2017,
  author       = {Bachoc, Fran{\c{c}}ois and Contal, Emile and Maatouk, Hassan and Rulli{\`{e}}re, Didier},
  title        = {Gaussian processes for computer experiments},
  journaltitle = {{ESAIM}: Proceedings and Surveys},
  date         = {2017},
  editor       = {Jean-Fran{\c{c}}ois Coeurjolly and Adeline Leclercq-Samson},
  volume       = {60},
  pages        = {163--179},
  doi          = {10.1051/proc/201760163},
  file         = {:bachoc2017 - Gaussian Processes for Computer Experiments.pdf:PDF},
  publisher    = {{EDP} Sciences},
  timestamp    = {2018-11-27},
}

@Book{wiener1949,
  author    = {Wiener, Norbert},
  title     = {Extrapolation, Interpolation, and Smoothing of Stationary Time Series: With Engineering Applications},
  date      = {1949},
  publisher = {The MIT Press},
  isbn      = {9780262230025},
  keywords  = {rank1},
  timestamp = {2018-11-27},
}

@PhdThesis{wold1938,
  author      = {Wold, Herman},
  title       = {A study in the analysis of stationary time series},
  institution = {Almqvist \& Wiksell},
  date        = {1938},
  timestamp   = {2018-11-27},
}

@Article{hensman2013,
  author      = {James Hensman and Nicolo Fusi and Neil D. Lawrence},
  title       = {Gaussian Processes for Big Data},
  date        = {2013-09-26},
  eprint      = {http://arxiv.org/abs/1309.6835v1},
  eprintclass = {cs.LG},
  eprinttype  = {arXiv},
  abstract    = {We introduce stochastic variational inference for Gaussian process models. This enables the application of Gaussian process (GP) models to data sets containing millions of data points. We show how GPs can be vari- ationally decomposed to depend on a set of globally relevant inducing variables which factorize the model in the necessary manner to perform variational inference. Our ap- proach is readily extended to models with non-Gaussian likelihoods and latent variable models based around Gaussian processes. We demonstrate the approach on a simple toy problem and two real world data sets.},
  file        = {:http\://arxiv.org/pdf/1309.6835v1:PDF},
  keywords    = {cs.LG, stat.ML, rank1},
  timestamp   = {2018-11-27},
}

@InCollection{rakitsch2013,
  author    = {Rakitsch, Barbara and Lippert, Christoph and Borgwardt, Karsten and Stegle, Oliver},
  title     = {It is all in the noise: Efficient multi-task Gaussian process inference with structured residuals},
  booktitle = {Advances in Neural Information Processing Systems 26},
  year      = {2013},
  editor    = {C. J. C. Burges and L. Bottou and M. Welling and Z. Ghahramani and K. Q. Weinberger},
  publisher = {Curran Associates, Inc.},
  pages     = {1466--1474},
  url       = {http://papers.nips.cc/paper/5089-it-is-all-in-the-noise-efficient-multi-task-gaussian-process-inference-with-structured-residuals.pdf},
  file      = {:5089-it-is-all-in-the-noise-efficient-multi-task-gaussian-process-inference-with-structured-residuals.pdf:PDF},
  timestamp = {2018-11-27},
}

@InProceedings{damianou2013,
  author    = {Damianou, Andreas and Lawrence, Neil},
  title     = {Deep gaussian processes},
  booktitle = {Artificial Intelligence and Statistics},
  date      = {2013},
  pages     = {207--215},
  file      = {:damianou2013 - Deep Gaussian Processes.pdf:PDF},
  timestamp = {2018-11-27},
}

@Misc{khan2012,
  author    = {Emtiyaz Khan, Shakir Mohamed, Kevin P. Murphy},
  editor    = {F. Pereira and C. J. C. Burges and L. Bottou and K. Q. Weinberger},
  title     = {Fast Bayesian Inference for Non-Conjugate Gaussian Process Regression},
  date      = {2012},
  url       = {http://papers.nips.cc/paper/4535-fast-bayesian-inference-for-non-conjugate-gaussian-process-regression.pdf},
  abstract  = {Neural Information Processing Systems http://nips.cc/},
  booktitle = {Advances in Neural Information Processing Systems 25},
  file      = {:khan2012 - Fast Bayesian Inference for Non Conjugate Gaussian Process Regression.pdf:PDF},
  pages     = {3140--3148},
  publisher = {Curran Associates, Inc.},
  timestamp = {2018-11-27},
}

@InCollection{neal1996,
  author    = {Neal, Radford M.},
  title     = {Priors for Infinite Networks},
  booktitle = {Bayesian Learning for Neural Networks},
  year      = {1996},
  publisher = {Springer New York},
  pages     = {29--53},
  doi       = {10.1007/978-1-4612-0745-0_2},
  file      = {:radford priors.pdf:PDF},
  timestamp = {2018-11-28},
}

@Misc{chollet2015,
  author       = {Chollet, Fran\c{c}ois and others},
  title        = {Keras},
  year         = {2015},
  howpublished = {\url{https://keras.io}},
  timestamp    = {2018-11-29},
}

@InCollection{rasmussen2004,
  author    = {Carl Edward Rasmussen},
  title     = {Gaussian Processes in Machine Learning},
  booktitle = {Advanced Lectures on Machine Learning},
  year      = {2004},
  publisher = {Springer Berlin Heidelberg},
  pages     = {63--71},
  doi       = {10.1007/978-3-540-28650-9_4},
  file      = {:rass.pdf:PDF},
  timestamp = {2018-11-29},
}

@Article{robert2014,
  author       = {Christian Robert},
  title        = {Machine Learning, a Probabilistic Perspective},
  journaltitle = {{CHANCE}},
  date         = {2014-04},
  volume       = {27},
  number       = {2},
  pages        = {62--63},
  doi          = {10.1080/09332480.2014.914768},
  publisher    = {Informa {UK} Limited},
  timestamp    = {2018-11-29},
}

@Book{murphy2012,
  author    = {Murphy, Kevin P.},
  title     = {Machine Learning: A Probabilistic Perspective},
  year      = {2012},
  date      = {2012-08-24},
  publisher = {MIT Press Ltd},
  isbn      = {0262018020},
  pagetotal = {1104},
  url       = {https://www.ebook.de/de/product/19071158/kevin_p_murphy_machine_learning.html},
  ean       = {9780262018029},
  file      = {:murphy.pdf:PDF},
  timestamp = {2018-11-29},
}

@Book{minsky1987,
  author    = {Marvin Minsky and Seymour A. Papert},
  title     = {Perceptrons: An Introduction to Computational Geometry, Expanded Edition},
  year      = {1987},
  publisher = {The MIT Press},
  isbn      = {0-262-63111-3},
  timestamp = {2018-12-02},
}

@Article{olazaran1996,
  author       = {Mikel Olazaran},
  title        = {A Sociological Study of the Official History of the Perceptrons Controversy},
  journaltitle = {Social Studies of Science},
  date         = {1996},
  volume       = {26},
  number       = {3},
  pages        = {611--659},
  issn         = {0306-3127},
  url          = {http://www.jstor.org/stable/285702},
  abstract     = {In this paper, I analyze the controversy within Artificial Intelligence (AI) which surrounded the 'perceptron' project (and neural nets in general) in the late 1950s and early 1960s. I devote particular attention to the proofs and arguments of Minsky and Papert, which were interpreted as showing that further progress in neural nets was not possible, and that this approach to AI had to be abandoned. I maintain that this official interpretation of the debate was a result of the emergence, institutionalization and (importantly) legitimation of the symbolic AI approach (with its resource allocation system and authority structure). At the 'research-area' level, there was considerable interpretative flexibility. This interpretative flexibility was further demonstrated by the revival of neural nets in the late 1980s, and subsequent rewriting of the official history of the debate.},
  file         = {:olazaran1996 - A Sociological Study of the Official History of the Perceptrons Controversy.pdf:PDF},
  publisher    = {Sage Publications, Ltd.},
  timestamp    = {2018-12-03},
}

@Article{alom2018,
  author       = {Alom, Md. Zahangir and Taha, Tarek M. and Yakopcic, Christopher and Westberg, Stefan and Hasan, Mahmudul and Esesn, Brian C. Van and Awwal, Abdul A. S. and Asari, Vijayan K.},
  title        = {The History Began from AlexNet: {A} Comprehensive Survey on Deep Learning Approaches},
  journaltitle = {CoRR},
  date         = {2018},
  volume       = {abs/1803.01164},
  eprint       = {1803.01164},
  eprinttype   = {arXiv},
  url          = {http://arxiv.org/abs/1803.01164},
  bibsource    = {dblp computer science bibliography, https://dblp.org},
  biburl       = {https://dblp.org/rec/bib/journals/corr/abs-1803-01164},
  file         = {:alom2018 - The History Began from AlexNet_ a Comprehensive Survey on Deep Learning Approaches.pdf:PDF},
  timestamp    = {Mon, 13 Aug 2018 16:46:09 +0200},
}

@Online{grey2017,
  author    = {Grey, C. G. P.},
  title     = {How Machines Learn},
  year      = {2017},
  url       = {https://www.youtube.com/watch?v=R9OHn5ZF4Uo},
  comment   = {Grey, C. G.P. “How Machines Learn.” YouTube, YouTube, 18 Dec. 2017, www.youtube.com/watch?v=R9OHn5ZF4Uo.},
  timestamp = {2018-12-03},
}

@Article{neal1998,
  author    = {Neal, Radford M.},
  title     = {Regression and classification using Gaussian process priors},
  journal   = {Bayesian statistics},
  year      = {1998},
  editor    = {Bernardo, J. M. and J. O. Berger, A. P. Dawid and Smith, A. F. M.},
  volume    = {6},
  pages     = {475},
  file      = {:val6gp.pdf:PDF},
  timestamp = {2018-12-07},
}

@Article{diggle2002,
  author    = {P. J. Diggle and J. A. Tawn and R. A. Moyeed},
  title     = {Model-based geostatistics},
  journal   = {Journal of the Royal Statistical Society: Series C (Applied Statistics)},
  year      = {2002},
  volume    = {47},
  number    = {3},
  month     = {jan},
  pages     = {299--350},
  doi       = {10.1111/1467-9876.00113},
  file      = {:diggle again.pdf:PDF},
  publisher = {Wiley},
  timestamp = {2018-11-28},
}

@Article{li2018,
  author    = {Li, Tong and Katz, Randy H. and Culler, David E.},
  title     = {ConNect: Exploring Augmented Reality Service using Image Localization and Neural Network Object Detection},
  date      = {2018},
  file      = {:li2018 - ConNect_ Exploring Augmented Reality Service Using Image Localization and Neural Network Object Detection.pdf:PDF},
  timestamp = {2018-12-07},
}

@InProceedings{gerla2014,
  author    = {M. Gerla and E. Lee and G. Pau and U. Lee},
  title     = {Internet of vehicles: From intelligent grid to autonomous cars and vehicular clouds},
  booktitle = {2014 IEEE World Forum on Internet of Things (WF-IoT)},
  year      = {2014},
  publisher = {IEEE},
  month     = {3},
  pages     = {241-246},
  doi       = {10.1109/WF-IoT.2014.6803166},
  file      = {:06803166.pdf:PDF},
  keywords  = {cloud computing;grid computing;Internet of Things;telecommunication computing;vehicular ad hoc networks;autonomous cars;vehicular clouds;intelligent vehicle grid;safe navigation;pollution control;traffic management;Google car;Internet of vehicles;Internet of Things;Internet cloud;VANET;Vehicles;Cloud computing;Roads;Mobile robots;Accidents;Cameras},
  timestamp = {2018-12-07},
}

@Book{rasmussen1997,
  author    = {Rasmussen, Carl Edward},
  title     = {Evaluation of Gaussian processes and other methods for non-linear regression},
  date      = {1997},
  publisher = {University of Toronto},
  file      = {:rasmussen1997 - Evaluation of Gaussian Processes and Other Methods for Non Linear Regression.pdf:PDF},
  timestamp = {2018-12-10},
}

@Book{gandin1963,
  author    = {Gandin, Lev Semenovich},
  title     = {Объективный анализ метеорологических полей (Objective analysis of meteorological fields)},
  year      = {1963},
  volume    = {287},
  publisher = {Гидрометеоиздат Ленинград (Gidrometeoizdat)},
  timestamp = {2018-12-10},
}

@Article{ramachandran2017,
  author      = {Prajit Ramachandran and Barret Zoph and Quoc V. Le},
  title       = {Searching for Activation Functions},
  date        = {2017-10-16},
  eprint      = {http://arxiv.org/abs/1710.05941v2},
  eprintclass = {cs.NE},
  eprinttype  = {arXiv},
  abstract    = {The choice of activation functions in deep networks has a significant effect on the training dynamics and task performance. Currently, the most successful and widely-used activation function is the Rectified Linear Unit (ReLU). Although various hand-designed alternatives to ReLU have been proposed, none have managed to replace it due to inconsistent gains. In this work, we propose to leverage automatic search techniques to discover new activation functions. Using a combination of exhaustive and reinforcement learning-based search, we discover multiple novel activation functions. We verify the effectiveness of the searches by conducting an empirical evaluation with the best discovered activation function. Our experiments show that the best discovered activation function, $f(x) = x \cdot \text{sigmoid}(\beta x)$, which we name Swish, tends to work better than ReLU on deeper models across a number of challenging datasets. For example, simply replacing ReLUs with Swish units improves top-1 classification accuracy on ImageNet by 0.9\% for Mobile NASNet-A and 0.6\% for Inception-ResNet-v2. The simplicity of Swish and its similarity to ReLU make it easy for practitioners to replace ReLUs with Swish units in any neural network.},
  file        = {:http\://arxiv.org/pdf/1710.05941v2:;:1710.05941.pdf:PDF},
  keywords    = {cs.NE, cs.CV, cs.LG},
  timestamp   = {2018-12-10},
}

@Article{rumelhart1986a,
  author       = {Rumelhart, David E. and Hinton, Geoffrey E. and Williams, Ronald J.},
  title        = {Learning representations by back-propagating errors},
  journaltitle = {Nature},
  date         = {1986},
  volume       = {323},
  number       = {6088},
  pages        = {533},
  file         = {:rumelhart1986a - Learning Representations by Back Propagating Errors.pdf:PDF},
  publisher    = {Nature Publishing Group},
  timestamp    = {2018-12-12},
}

@InProceedings{herbrich2003,
  author    = {Herbrich, Ralf and Lawrence, Neil D and Seeger, Matthias},
  title     = {Fast sparse Gaussian process methods: The informative vector machine},
  booktitle = {Advances in neural information processing systems},
  date      = {2003},
  pages     = {625--632},
  file      = {:herbrich2003 - Fast Sparse Gaussian Process Methods_ the Informative Vector Machine.pdf:PDF},
  timestamp = {2018-12-12},
}

@Article{christin2015,
  author        = {Christin, Agn{\`e}le and Rosenblat, Alex and Boyd, Danah},
  title         = {Courts and predictive algorithms},
  journal       = {Data \& CivilRight},
  year          = {2015},
  __markedentry = {[Hannes:]},
  timestamp     = {2018-12-12},
}

@InProceedings{bennett2007,
  author        = {Bennett, James and Lanning, Stan and others},
  title         = {The Netflix Prize},
  booktitle     = {Proceedings of KDD cup and workshop},
  year          = {2007},
  volume        = {2007},
  organization  = {New York, NY, USA},
  pages         = {35},
  __markedentry = {[Hannes:6]},
  timestamp     = {2018-12-12},
}

@Article{chao2018,
  author    = {Chao, Xiangrui and Kou, Gang and Li, Tie and Peng, Yi},
  title     = {Jie Ke versus {AlphaGo}: A ranking approach using decision making method for large-scale data with incomplete information},
  journal   = {European Journal of Operational Research},
  year      = {2018},
  volume    = {265},
  number    = {1},
  month     = {feb},
  pages     = {239--247},
  doi       = {10.1016/j.ejor.2017.07.030},
  publisher = {Elsevier {BV}},
  timestamp = {2018-12-12},
}

@Article{cortez2013,
  author    = {Paulo Cortez and Mark J. Embrechts},
  title     = {Using sensitivity analysis and visualization techniques to open black box data mining models},
  journal   = {Information Sciences},
  year      = {2013},
  volume    = {225},
  month     = {mar},
  pages     = {1--17},
  doi       = {10.1016/j.ins.2012.10.039},
  file      = {:1-s2.0-S0020025512007098-main.pdf:PDF},
  publisher = {Elsevier {BV}},
  timestamp = {2018-12-13},
}

@Article{castelvecchi2016,
  author    = {Davide Castelvecchi},
  title     = {Can we open the black box of {AI}?},
  journal   = {Nature},
  year      = {2016},
  volume    = {538},
  number    = {7623},
  month     = {oct},
  pages     = {20--23},
  doi       = {10.1038/538020a},
  publisher = {Springer Nature},
  timestamp = {2018-12-13},
}

@Article{mahendran2014,
  author      = {Mahendran, Aravindh and Vedaldi, Andrea},
  title       = {Understanding Deep Image Representations by Inverting Them},
  date        = {2014-11-26},
  eprint      = {http://arxiv.org/abs/1412.0035v1},
  eprintclass = {cs.CV},
  eprinttype  = {arXiv},
  abstract    = {Image representations, from SIFT and Bag of Visual Words to Convolutional Neural Networks (CNNs), are a crucial component of almost any image understanding system. Nevertheless, our understanding of them remains limited. In this paper we conduct a direct analysis of the visual information contained in representations by asking the following question: given an encoding of an image, to which extent is it possible to reconstruct the image itself? To answer this question we contribute a general framework to invert representations. We show that this method can invert representations such as HOG and SIFT more accurately than recent alternatives while being applicable to CNNs too. We then use this technique to study the inverse of recent state-of-the-art CNN image representations for the first time. Among our findings, we show that several layers in CNNs retain photographically accurate information about the image, with different degrees of geometric and photometric invariance.},
  file        = {:http\://arxiv.org/pdf/1412.0035v1:PDF},
  keywords    = {cs.CV},
  timestamp   = {2018-12-13},
}
