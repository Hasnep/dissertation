% !TeX root = ..\dissertation.tex

\chapter{Machine Learning}

We are in an age where there is so much data that in many cases, hand building a model to analyse, find patterns in and draw conclusions from the data is unfeasible, and so we use computers to analyse it in a process called \qt{Machine Learning} (ML)~\autocite[1]{murphy2012}.
Computers are able to do these tasks by combining information in nonlinear ways, but become more powerful when the output of one nonlinear process is fed into another nonlinear process, abstracting the raw data to a higher level.
\qtc[436]{lecun2015}{With the composition of enough such transformations, very complex functions can be learned}.

\section{Neural Networks}

\subsection{The Neuron}

\begin{todo}
	Each neuron performs a weighted sum 
\end{todo}

\begin{figure}[htbp]
	\centering
	\includegraphics[width=\textwidth]{example-image-golden.pdf}
	\caption{A diagram of an example artificial neuron.}
	\label{fig:neuron-example}
\end{figure}

\subsection{Neural network layers and Backpropagation}

\begin{todo}
	Neurons are connected in layers. \\
	Backpropagation is used to optimise the weights. \\
	Batch backpropagation of all the datapoints takes too long. \\
	Online BP is faster but takes more steps. \\
	Stochastic minibatches can be used to speed up calculations. 
\end{todo}

The weights in a neural network are optimised using the backpropagation algorithm.

\begin{todo}
	Fix my explanation of the backpropagation algorithm.
\end{todo}

\note{Is it possible to add a title to an enumerate?}
For a neural network with \(N\) weights
\begin{enumerate}
	\item Randomly initialise all the weights \(\vec{w} = w_1, \dots, w_N\).
	\item Predict the outputs \(\vec{y}^\text{pred} = y^\text{pred}_1, \dots, y^\text{pred}_n\) using the training data \(X = (\vec{x}_1, \dots, \vec{x}_n)\).
	\item Calculate the error vector \(\vec{\epsilon} = \vec{y}^\text{pred} - \vec{y}^\text{target}\). The error only depends on the output of .
	\item Calculate the gradient of the error \(\vec{\Delta} = \pdv{\vec{\epsilon}}{\vec{w}}\). \(\vec{\Delta}\) represents the direction in \(N\)-dimensional space .
	\item Update the weights \(\vec{w} \leftarrow \).
\end{enumerate}

To understand the backpropagation algorithm, consider a network with only one output neuron (such as in Figure~\ref{examplenn}), and consider its prediction for a specific datapoint in the training set.
The squared error for this datapoint is \(\varepsilon = \left(y^\text{target} - y^\text{prediction}\right)^2\).
The target is fixed, and we cannot directly change the prediction, so to reduce \(\varepsilon\), we can calculate the change we need to make to each weight to reduce the error the most.
The prediction only depends on the outputs of the neurons on the previous layer and the weights connecting the layers.
This same logic applies to all of the neurons in the network.
Assuming that all the activation functions are differentiable, we can apply the chain rule repeatedly to calculate the gradient of the overall error with respect to each weight \(w_j\) in the network.
This gradient
\[ \Delta w_j = \pdv{\varepsilon(w_j)}{w_j} \]
represents the change needed to weight \(w_j\) to most steeply increase the error, so the value \(-\Delta w_j\) is the direction that most steeply decreases the error.
We scale this amount by a constant hyperparameter \(\eta\), called the \qt{learning rate}, and change each weight accordingly \(w_j = w_j - \eta \Delta w_j\).
We perform this process for each weight, and then for each datapoint in the training dataset.

This type of method is called \qt{stochastic gradient descent} (also called \qt{online gradient descent} or \qt{iterative gradient descent}) because it does not calculate the true steepest gradient.
Each datapoint moves the weights in a slightly different direction, so the optimisation process zigzags towards the optimum, rather than taking the steepest path.
An alternative is \qt{batch gradient descent}, where the sum of the squared errors for all the training data is calculated and optimised.
\[ \varepsilon(\vec{w}) = \frac{1}{2} \sum_{i}\left(y_i^\text{target} - y_i^\text{output}\right)^2 \]
This will converge to a solution in fewer steps, but takes significantly longer to compute.

Estimating the parameters of an \ac{ANN} using either type of gradient descent is guaranteed to find a local optimum given enough time, but is not guaranteed to converge to a global optimum.
It is quite rare for the algorithm to get trapped in a local minimum, but a more common problem is getting stuck at saddle points where the gradient is zero~\autocite[438]{lecun2015}.

\section{Deep Learning}

\begin{todo}
	DL is just ML with more layers
\end{todo}

\note{Rewrite this to more slowly introduce deep learning and be more generally about machine learning than ANNs}
As computing power has increased exponentially following Moore's law, machine learning has become a more viable and effective method of prediction.
In the 21st century, success has been found in increasing the number of layers in a neural network or other machine learning method rather than the complexity of each layer.
These \qt{deep neural networks} \qtc[438]{lecun2015}{can implement extremely intricate functions of its inputs that are simultaneously sensitive to minute details}.

\section{Modern techniques/tools}

\ac{DL} has even made its way into consumer products.
Many modern phones have facial recognition software built in, and \ac{AI} voice assistants are becoming more common in homes.

\ac{DL} is also becoming more accessible, with the release of Google's \qt{Tensorflow} package for \ac{DL}~\autocite{abadi2016}, which is now available as \qt{Keras}, a user friendly package for Python~\autocite{chollet2015} and R~\autocite{allaire2018}.

\section{Example}

To demonstrate the possibility of using statistical methods to understand the process of deep learning, we use a simple function \(f(x) = x + 5 \sin(x)\).
256 evenly spread datapoints were taken from this function, and noise following \(\epsilon \distributed \normdist(0, 0.1)\) was applied.

\begin{todo}
Possibly also use a more complex example?
\end{todo}

\subsection{Training a neural network}

This function was learnt by a neural network with 8 layers, each with 10 neurons and the \(\tanh(\cdot)\) activation function, except for the final layer which used a linear activation function.
The result of this learning is seen in Figure~\ref{fig:ann-output}.

\begin{figure}[htbp]
	\centering
	\includegraphics[width=\textwidth]{example-image-golden.pdf}
	\caption{The output of the neural network.}
	\label{fig:ann-output}
\end{figure}

\begin{todo}
Information on choosing the right size NN
\end{todo}

\subsection{Ordering of the datapoints}

Due to the form of stochastic gradient descent used to train the model, if the order of the datapoints is not randomised, then the optimisation algorithm is significantly more likely to get stuck in a local minimum.
An example of this is seen in Figure~\ref{fig:ann-order}, where the same neural network has been trained on the example data which has been shuffled, reversed, randomised and separated.

\begin{figure}[htbp]
	\centering
	\includegraphics[width=\textwidth]{example-image-golden.pdf}
	\caption{The output of the same neural network trained on the same data but ordered differently.}
	\label{fig:ann-order}
\end{figure}

\textcite{bengio2009} developed a technique called \qt{curriculum learning} which uses this fact to improve training by starting with easier training examples.
