% !TeX root = ../dissertation.tex

\chapter{Opening the black box}

The fact that predicting from a neural network consists of many simple operations in a hierarchical structure suggests that it could be possible to mathematically or statistically explain or approximate their output.
Directly understanding the meaning of each weight in a neural network is impossible for a human.
Even the neural network used to learn the simple example in this project seen in Figure~\ref{fig:final-ann-architecture} is far too complex to keep track of.

\section{Current and past research}

When neural networks were first trained on image classification problems, it was thought that each layer would successively combine features from the previous layer to form more complex structures.
For example, a common machine learning problem is designing a neural network for classifying handwritten digits where the input is a vector of length \(n^2\) representing the brightness of each pixel in an \(n \times n\) image.
A designer might plan for the first layer to pick out clusters of pixels, then the next layer would combine adjacent clusters into lines, the next layer would combine lines into corners, and the final layer would identify combinations of lines and corners as digits.
However, once a neural network is trained on such a problem, each neuron is activated by a seemingly random set of pixels spread across the image.
For this reason, it is almost impossible to give meaning to any neuron in the neural network as was originally hypothesised.

\textcite{mahendran2014} trained a deep neural network on images and attempted to \qt{invert} it to reconstruct the original inputs.
They found that each successive layer abstracts the data, but isolating the specific neurons responsible for specific objects or ideas was more difficult.

Sensitivity analysis has also been used to evaluate the importance of each input to a neural network in the final output, and the results visualised as a decision tree where each branch represents a range of input values~\autocite[13]{cortez2013}.

\section{Multiple regression}

An ideal way to understand a deep neural network would be to find the form of a function that describes the output of the neural network.
One way of doing this is to use multiple regression with a series of basis functions on the output of the neural network.
A new dataset is generated by using the neural network to predict the target values in the domain that it was trained on.
Then, many basis functions are calculated and traditional linear regression is used on the resulting matrix of predictors in an attempt to uncover which are the \qt{true} functions that the neural network is trying to approximate.
The number of basis functions can be increased arbitrarily, but this will increase the fitting time.
This technique also requires regularisation to reduce the number of terms in the model, as there will likely be many terms with small coefficients that are determined to be significant.

In this case, the basis functions \(1\), \(x\), \(x^2\), \(\sin(x)\), \(\sin(2x)\), \(\sin(x/2)\), \(\cos(x)\), \(\cos(2x)\) and \(\cos(x/2)\) were used, where the desired output is that \(x\) and \(\sin(x)\) will be selected as significant and ideally have coefficients close to 1 and 5 respectively and the other terms will have coefficients close to zero.
In this situation, the exact \qt{true} terms are known, but in a more realistic application where the form of the input function is completely unknown, many more terms could be fitted including higher order polynomials and interactions between predictors.
Due to the imperfect fit of the neural network, it is unlikely that the desired coefficients will be selected exactly, so other terms will have non-zero coefficients to slightly adjust the model's fit.

Table~\ref{tab:multiple-regression} shows a summary of the fit of the regression model.
There are many terms with coefficients close to zero which could be ignored as they do not contribute much to the fit, although almost all of the terms have \(t\)-values in the extreme tails of the distribution.

\includetable{multiple-regression}

This model requires regularisation to reduce the number of terms and to determine which of the insignificant terms to remove.

\begin{figure}[htbp]
	\centering
	\includesvg[width=\figwidth]{multiple-regression-fit}
	\caption{The fit of the multiple regression model.}
	\label{fig:multiple-regression-fit}
\end{figure}

\subsection{Stepwise regression}

One way to regularise the model is to use stepwise regression to reduce the number of parameters.
\reword{It does this by} adding or removing one term at a time and comparing the fit of the nested models.
In this case, the variables were selected using the \ac{AIC}, which penalises the fit for having a higher number of coefficients.
For this example, forward selection, where the initial model is empty and a term is added at each step, and backward selection, which starts with a full model and removes a term at each step, were used, both arrived at similar models, but the method with the lowest \ac{AIC} was to use both forward and backward selection.
Table~\ref{tab:stepwise-regression} shows a summary of the reduced model.
\includetable{stepwise-regression}
The intercept and \(\cos(2x)\) terms were removed from the full model.
The coefficients of some of the reduced model are slightly different from the full model to compensate for the removed terms, as seen in Table~\ref{tab:compare-coefs}.

While the relevant estimators \(x\) and \(\sin(x)\) were identified and their coefficients fairly accurately estimated, a few other variables were also identified as significant.
This method is only likely to work with a perfect or near perfect fit with no noise, which is unrealistic for real applications.

\begin{figure}[htbp]
	\centering
	\includesvg[width=\figwidth]{stepwise-regression-fit}
	\caption{The fit of the stepwise model.}
	\label{fig:stepwise-regression-fit}
\end{figure}

\subsection{LASSO}

Alternatively, we can use \ac{LASSO} regularisation to select the significant variables from the full model.
The \ac{LASSO} constrains the sum of the absolute values of the model parameters, regularising the least influential parameters to zero.
We vary the hyperparameter \(\lambda\) to change the trade off between simplicity and fit accuracy, as seen in Figure~\ref{fig:lasso-lambda}.
We then use leave-one-out cross-validation to find the optimal hyperparameter \(\lambda\), the results of which can be seen in Table~\ref{tab:lasso-coefs}.

\begin{figure}[htbp]
	\centering
	\includesvg[width=\figwidth]{lasso-lambda}
	\caption{The effect on the coefficients when changing the regularisation hyperparameter \(\lambda\).}
	\label{fig:lasso-lambda}
\end{figure}

\includetable{lasso-coefs}

\subsection{Comparison}

Table~\ref{tab:compare-coefs} shows a comparison between the coefficients selected by the full model and the two regularisation methods.

\includetable{compare-coefs}

\section{Gaussian processes}

One proposed way to better understand deep learning is by using \acp{GP} to approximate the output of a deep learning algorithm.
It has been shown that \reword{as the number of neurons in a layer of a} neural network approaches infinity, the fit of the layer approaches a \ac{GP}~\autocite{neal1996}.

\reword{In a similar way to how a} univariate normal distribution with a mean and variance can be generalised to a multivariate normal distribution with a mean vector and a normal vector, a \ac{GP} is the limit of extending a multivariate normal distribution to infinite dimensions, with a mean function and covariance function (sometimes also called a kernel in machine learning environments) which depends on the distance between two points.

A random vector \(X \in \reals{}^n\) is distributed with a multivariate normal distribution in \(n\) dimensions with mean vector \(\vec{\mu} \in \reals{}^n\) and covariance matrix \(K \in \reals^{n \times n}\) if \(X \distributed \normdist(\vec{\mu},\, K)\).
In a similar way, \(Y\) is a \ac{GP} with a mean function \(\mu\) and a covariance function \(k\) where \(k(x_1, x_2) = k(\left|x_1 - x_2\right|)\) if \(Y \distributed \gp(\mu,\, k)\).
Because a \ac{GP} is an extension of a multivariate normal distribution, any finite subset of points from a \ac{GP} has a multivariate normal distribution~\autocite[515]{williams1996}.

There appears to be no literature on using \acp{GP} as a way to better understand how deep learning algorithms work or as a way to understand their structure, although there has been a fierce debate over the advantages of both neural networks and \acp{GP} since at least the 1990s.
\textcite[65--66]{rasmussen1997} gave evidence that \acp{GP} are a valid replacement for neural networks in nonlinear problems with fewer than 1000 datapoints, although due to advances in processing power, neural network algorithms and \ac{GP} techniques, this recommendation will likely have changed.
\textcite[25]{mackay1997} gave an example of \acp{GP} being used for binary classification, in a similar way to neural networks.
When \ac{GPR} and neural networks are compared, \reword{the main advantages mentioned} are usually faster convergence and confidence or credible intervals for the predictions, which neural networks cannot do~\autocite{herbrich2003}.


\subsection{Using Gaussian process regression}
\begin{todo}
	Explain how a GP will help us understand the neural network. \\
	GPs have statistical properties that we understand, so if we can fit a GP and then calculate these properties we can apply our knowledge to the neural network.
\end{todo}

\subsection{Using Gaussian process regression}

Because \acp{GP} are very flexible, applying a \ac{GP} to the output of the neural network is likely to result in a close fit.

\begin{figure}[htbp]
	\centering
	\includesvg[width=\figwidth]{gp-fit}
	\caption{The fit of the \ac{GP} (\gpcolour) and the true function (\truthcolour).}
	\label{fig:gp-fit}
\end{figure}

The fit of the \ac{GP} is almost perfect, as expected.

\begin{todo}
	give some sort of quantitative explanation of how well the GP has fitted \\
	explain how the GP can now be used
\end{todo}

