% !TeX root = ..\dissertation.tex

\chapter{Introduction}

\section{What is machine learning?}
\begin{todo}
	Machine learning is very complex to human understanding \\
	Machine learning is widely used in many high stakes scenarios --- give examples \\
	It is important to be able to look inside the `black box' of machine learning --- explain how this would be useful in each of the given examples \\
	We can use statistical methods to try and recover the information in a ML algorithm --- give some idea how
\end{todo}
   
    

Since the turn of the millennium, machine learning, and particularly deep learning have been able to solve many problems that were once thought impossible for a computer.
Machines can now identify objects~\autocite{li2018}, beat humans at PSPACE-hard games such as Go~\autocite{chao2018} and even drive cars~\autocite{gerla2014}.
These tasks are so complex that designing an algorithm by hand to tackle them would be impossible, so instead, we create a set of instructions to train a model.
One of these \qt{machine learning} algorithms is the artificial neural network, which takes inspiration from the neural structure of biological brains.
Artificial neural networks consist of units called \qt{neurons}, which individually perform a simple nonlinear operation, but when connected, can learn complex nonlinear patterns.
Due to the abstracted nature of a machine learning algorithm's calculations, it can be difficult to provide a human understandable explanation for its reasoning, and often it is impossible.
\qtc{grey2017}{While an individual neuron may be understood, and clusters of neurons' general purpose vaguely grasped, the whole is beyond. Nonetheless, it works}.

As these algorithms are placed in more real world scenarios in control of important infrastructure and even human lives, the ability to understand what is happening inside the \qt{black box} becomes more important.
Autonomous vehicles are becoming more ubiquitous, which will be faced with edge cases which no human could have predicted.
In cases where a driverless car does something unforeseen, it will be useful to have some understanding of what the algorithm was \qt{thinking} when it made the decision.
Machine learning systems which aid in probation and parole decisions in the U.S.\ are now being trialled for sentencing, but have come under a lot of criticism for being racially biased~\autocite{christin2015}.
The question of how an algorithm can be \qt{held accountable} has been raised~\autocite[9]{christin2015}, but it is not known what accountability looks like for an unintelligible artificial mind.
