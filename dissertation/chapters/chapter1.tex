% !TeX root = ..\dissertation.tex

\chapter{Introduction}

\section{What is machine learning?}
\begin{todo}
	Machine learning is very complex to human understanding \\
	Machine learning is widely used in many high stakes scenarios --- give examples \\
	It is important to be able to look inside the `black box' of machine learning --- explain how this would be useful in each of the given examples \\
	We can use statistical methods to try and recover the information in a ML algorithm --- give some idea how
\end{todo}

Since the turn of the millennium, \ac{ML}, and particularly \ac{DL} have been able to solve many problems that were once thought impossible for a computer.
Machines can now identify objects~\autocite{li2018}, beat humans at PSPACE-hard games such as Go~\autocite{chao2018} and even drive cars~\autocite{gerla2014}.
These tasks are so complex that designing an algorithm by hand to \reword{tackle} them would be impossible, so instead, we design a process that teaches the machine to find patterns and respond intelligently~\autocite[1]{murphy2012}.
One of these \ac{ML} algorithms is the artificial neural network, which takes inspiration from the neural structure of biological brains.
Artificial neural networks consist of units called \qt{neurons}, which individually perform a simple nonlinear operation, but when interconnected can understand more complex structures~\autocite[436]{lecun2015}.
Due to the abstracted nature of \iac{ML} algorithm's calculations, it can be difficult to provide a human understandable explanation for its reasoning, and often it is impossible.
% \qtc{grey2017}{While an individual neuron may be understood, and clusters of neurons' general purpose vaguely grasped, the whole is beyond. Nonetheless, it works}.

As these algorithms are placed in more real world scenarios and in control of important infrastructure and even human lives, the need to understand what is happening inside the \qt{black box} becomes more important.
Autonomous vehicles are becoming more common, and will be faced with edge cases which no human could have predicted.
In cases where a driverless car does something unforeseen, it will be useful to have some understanding of what the algorithm was \qt{thinking} when it made the decision.
\ac{ML} systems which aid in probation and parole decisions in the U.S.\ are now being trialled for sentencing, but have come under a lot of criticism for being racially biased~\autocite{christin2015}.
The question of how an algorithm can be \qt{held accountable} has been raised~\autocite[9]{christin2015}, but it is not known what accountability looks like for an artificial mind.
